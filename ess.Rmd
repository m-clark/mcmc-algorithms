# <a name='ess'>Elliptical Slice Sampler</a>

(<a name='ess'>ESS</a>)

<br>
```{r, echo=FALSE}
pander::pander(
  data.frame(
    Aspect = c('Acceptance Rate', 'Applications', 'Difficulty', 'Final Algorithm?', 'Proposal'),
    Description = c('The acceptance rate is 1.', 'This algorithm is applicable only to models in which the prior mean of all parameters is zero.','This algorithm is easy for a beginner. There is only one optional algorithm specification for block updating, and tuning is unnecessary, though optimal performance is gained with a user-specified prior covariance matrix for the ellipse.','Yes.', 'Multivariate.')),
  justify='left', style='multiline', split.cells=c(17,83), split.tables=Inf)
```

<br>

Elliptical Slice Sampling (ESS) was introduced by Murray et al. (2010) as a multivariate extension of componentwise Slice sampling (Slice) that utilizes ellipse ν and angle θ. Each iteration, ellipse ν is drawn from N(0, Σ), where Σ is a user-specified prior covariance for the ellipse. The authors recommend using a form of the covariance of the data. Even though other parameters are not discussed, an identity matrix, or a combination thereof, performs well in practice. The prior covariance matrix is accepted as `VarCov` in the <span class="func">LaplacesDemon</span> function, rather than the usual proposal covariance matrix.

ESS has one algorithm specification `B` for blocks of parameters, and defaults to `B=NULL`. For large-dimensional problems, block updating may be used. To specify block updating, the user gives the `B` specification a list in which each component is a block, and each component is a vector of integers pointing to the position of the parameters for that block. Block updating also requires the `Covar` argument to receive a list of prior covariance matrices of the appropriate dimension.

Each proposal is an additive, trigonometric function of the current state, ellipse ν, and angle θ. Angle θ is originally in the interval (0, 2π] each iteration, and is shrunk until acceptance occurs. This results in a 100% acceptance rate, and usually multiple model evaluations per iteration.

This algorithm is applicable only to models in which the prior mean of all parameters is zero. It is often possible to apply ESS when the variables are centered and scaled.

An advantage of ESS over the (componentwise) Slice algorithm is the computational efficiency of a multivariate proposal. A disadvantage is that the user must specify the prior covariance Σ for optimal ESS performance, and the algorithm can be very sensitive to this prior. Since ESS is not adaptive, it is suitable as a final algorithm.

## References

- Murray I, Adams R, KacKay D (2010). "Elliptical Slice Sampling." Journal of Machine Learning Research, 9, 541-548.


## See Also

- [Slice](#slice)

